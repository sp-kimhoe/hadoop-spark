# hadoop/Dockerfile
FROM mcr.microsoft.com/vscode/devcontainers/python:3.7-buster

# Install essential dependencies, including OpenSSH for inter-service communication
RUN apt-get update && \
    apt-get install -y software-properties-common curl bash coreutils procps openssh-server && \
    apt-get clean

# Download and install AdoptOpenJDK 8 (Temurin)
RUN mkdir -p /usr/share/man/man1 && \
    curl -fSL https://github.com/adoptium/temurin8-binaries/releases/download/jdk8u302-b08/OpenJDK8U-jdk_x64_linux_hotspot_8u302b08.tar.gz \
    | tar -xz -C /usr/local && \
    mv /usr/local/jdk8u302-b08 /usr/local/java8 && \
    ln -s /usr/local/java8/bin/java /usr/bin/java

# Set environment variables for Java and Hadoop
ENV JAVA_HOME=/usr/local/java8
ENV HADOOP_HOME=/usr/local/hadoop
ENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
ENV PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

# Download and install Hadoop
ARG HADOOP_VERSION=3.2.1
RUN curl -fSL https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz \
    | tar -xz -C /usr/local && \
    mv /usr/local/hadoop-${HADOOP_VERSION} /usr/local/hadoop

# Ensure correct permissions and create users for Hadoop services
RUN useradd -m hdfs && \
    useradd -m yarn && \
    chown -R hdfs:hdfs $HADOOP_HOME && \
    chown -R yarn:yarn $HADOOP_HOME

# Configure SSH for root and set up authorized keys for `hdfs` user
RUN ssh-keygen -q -N "" -t rsa -f ~/.ssh/id_rsa && \
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && \
    echo 'root:root' | chpasswd && \
    sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config && \
    mkdir -p /var/run/sshd

# Configure Hadoop environment in hadoop-env.sh
RUN echo "export JAVA_HOME=/usr/local/java8" >> $HADOOP_CONF_DIR/hadoop-env.sh && \
    echo "export HDFS_NAMENODE_USER=hdfs" >> $HADOOP_CONF_DIR/hadoop-env.sh && \
    echo "export HDFS_DATANODE_USER=hdfs" >> $HADOOP_CONF_DIR/hadoop-env.sh && \
    echo "export HDFS_SECONDARYNAMENODE_USER=hdfs" >> $HADOOP_CONF_DIR/hadoop-env.sh && \
    echo "export YARN_RESOURCEMANAGER_USER=yarn" >> $HADOOP_CONF_DIR/hadoop-env.sh && \
    echo "export YARN_NODEMANAGER_USER=yarn" >> $HADOOP_CONF_DIR/hadoop-env.sh

# Copy the start-hadoop.sh script
COPY start-hadoop.sh /usr/local/hadoop/start-hadoop.sh
RUN chmod +x /usr/local/hadoop/start-hadoop.sh

# Expose necessary Hadoop ports
EXPOSE 9870 9000 8088

# Start SSH service and Hadoop services using bash explicitly
CMD ["/bin/bash", "-c", "/usr/sbin/sshd && /usr/local/hadoop/start-hadoop.sh"]