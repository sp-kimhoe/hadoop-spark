# FROM alpine:3.9
FROM ubuntu:20.04

# Install necessary packages
RUN apt-get update && \
    apt-get install -y openjdk-8-jdk wget curl && \
    apt-get clean;
# RUN apk add --no-cache bash openjdk8 curl tar bash

# Set environment variables for Spark
ENV SPARK_VERSION 2.4.0
ENV HADOOP_VERSION 2.7
# ENV SPARK_HOME /usr/local/spark
# ENV PATH $PATH:$SPARK_HOME/bin
# Set environment variables for Java and Spark
ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
ENV PATH $JAVA_HOME/bin:$PATH

# Download and install Spark
RUN curl -L https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz | tar -xz -C /usr/local/ \
    && mv /usr/local/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION $SPARK_HOME

# Set Spark environment variables
ENV SPARK_HOME /usr/local/spark
ENV PATH $SPARK_HOME/bin:$PATH

# Expose Spark UI ports
EXPOSE 8080 7077 8081

# Start Spark Master process directly without nohup or nice
CMD ["/usr/local/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--host", "0.0.0.0", "--port", "7077", "--webui-port", "8080"]
